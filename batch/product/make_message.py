import json
import os
from datetime import datetime

import pandas as pd

from batch.product.keywords import BUTTON_TAG_MAP, CARD_COMPANIES, KEYWORDS_BY_BUTTON
from batch.product.prompt import (
    OTHER_PROMPT,
    OTHER_TEXT_INPUT,
    US_PROMPT,
    US_TEXT_INPUT,
)
from batch.product.utils import (
    fill_postdate_from_pubdate,
    filter_last_n_days_postdate,
)
from batch.scorer import extract_high_score_data
from batch.utils import read_csv
from batch.variables import (
    EXTRACTED_DATA_COUNT,
    PRODUCT_SAVE_PATH,
)
from bot.services.core.openai_client import openai_response
from logger import logger


def _identify_company(text: str) -> str:
    for company in CARD_COMPANIES:
        if company in text:
            return company
    return "ê¸°íƒ€"


def _to_json(df: pd.DataFrame) -> str:
    return json.dumps(
        df[["company", "title", "link", "description"]].to_dict(orient="records"),
        ensure_ascii=False,
    )


def _make_header(button_label: str, expected: int, actual: int) -> str:
    date = datetime.today().strftime("%Yë…„ %mì›” %dì¼")
    button_label_map: dict[str, tuple[str, str]] = {
        "ì‹ ìš©ì¹´ë“œ ì‹ ìƒí’ˆ": ("ê²½ìŸì‚¬ ì‹ ìƒí’ˆ", ""),
        "ì²´í¬ì¹´ë“œ ì‹ ìƒí’ˆ": ("ê²½ìŸì‚¬ ì‹ ìƒí’ˆ", ""),
        "ì›ë”ì¹´ë“œ ê³ ê°ë°˜ì‘": ("ìì‚¬ ì¤‘ì ìƒí’ˆ", "ì›ë”ì¹´ë“œ"),
        "JADE ê³ ê°ë°˜ì‘": ("ìì‚¬ ì¤‘ì ìƒí’ˆ", "JADE"),
    }
    product_type, title = button_label_map[button_label]
    return (
        f"ì•ˆë…•í•˜ì„¸ìš”, ì¤ì¤ì´ì…ë‹ˆë‹¤. {date} "
        f"ì¤ì¤í•œ {product_type} {title} ê³ ê° ë°˜ì‘ì„ ê³µìœ ë“œë¦´ê²Œìš”.\n\n"
        f"ìˆ˜ì§‘í•œ ë¬¸ì„œ {expected}ê°œ ì¤‘ ì˜ë¯¸ ìˆëŠ” {actual}ê°œë¥¼ ì§‘ì¤‘ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.\n"
    ).replace("  ", " ")


def _load_dataframes(tag: str) -> list[pd.DataFrame]:
    sources = ["news", "blog"]
    dfs: list[pd.DataFrame] = []

    for source in sources:
        path = os.path.join(PRODUCT_SAVE_PATH, f"{source}_{tag}.csv")
        if not os.path.exists(path):
            continue

        df = read_csv(path)
        if df is not None and not df.empty:
            df = fill_postdate_from_pubdate(df)
            dfs.append(df)

    return dfs


def _update_is_posted(tag: str, used_links: list[str]) -> None:
    if not used_links:
        return

    for source in ("news", "blog"):
        fpath = os.path.join(PRODUCT_SAVE_PATH, f"{source}_{tag}.csv")
        if not os.path.exists(fpath):
            continue

        df = read_csv(fpath)
        if df is None or df.empty or "link" not in df.columns:
            continue

        if "is_posted" not in df.columns:
            df["is_posted"] = 0

        mask = df["link"].astype(str).isin([str(u) for u in used_links])
        changed = int(mask.sum())
        if changed:
            df.loc[mask, "is_posted"] = 1
            try:
                df["is_posted"] = df["is_posted"].astype(int)
            except Exception:
                pass
            df.to_csv(fpath, index=False, encoding="utf-8")
        logger.info(f"{os.path.basename(fpath)}: is_posted updated {changed} rows")


def load_and_send_message(button_label: str) -> list[str]:
    """ë²„íŠ¼ ë¼ë²¨ì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬"""
    if button_label in ["ì›ë”ì¹´ë“œ ê³ ê°ë°˜ì‘", "JADE ê³ ê°ë°˜ì‘"]:
        return _handle_our_product(button_label)
    else:
        return _handle_competitor_product(button_label)


def _handle_competitor_product(button_label: str) -> list[str]:
    keywords = KEYWORDS_BY_BUTTON[button_label]
    tag = BUTTON_TAG_MAP[button_label]
    dfs = _load_dataframes(tag)

    if not dfs:
        logger.warning("No source files found.")
        return [f"[{button_label}]\nìµœê·¼ 7ì¼ ë‚´ ì†Œì‹ì´ ì—†ì–´ìš” ğŸ˜Š"]

    data = pd.concat(dfs, ignore_index=True)
    data = filter_last_n_days_postdate(data, 7)

    if data.empty:
        logger.warning("No data after 7-day postdate filter.")
        return [f"[{button_label}]\nìµœê·¼ 7ì¼ ë‚´ ì†Œì‹ì´ ì—†ì–´ìš” ğŸ˜Š"]
    total_count = len(data)

    data = data.rename(columns={"postdate": "post_date"})

    refined_data = extract_high_score_data(
        data, keywords, CARD_COMPANIES, EXTRACTED_DATA_COUNT
    )
    if len(refined_data) == 0:
        logger.warning("No data found after filtering.")
        return [
            "ì˜¤ëŠ˜ì€ íƒ€ì‚¬ ì‹ ìƒí’ˆ ê´€ë ¨ ì£¼ëª©í• ë§Œí•œ ì´ìŠˆê°€ ì—†ì–´ìš”! ë‹¤ìŒì— ë” ì¢‹ì€ ì´ìŠˆë¡œ ì°¾ì•„ì˜¬ê²Œìš” ğŸ˜Š"
        ]

    refined_data["company"] = refined_data["title"].apply(_identify_company)
    actual_count = len(refined_data)
    companies = ", ".join(sorted(set(refined_data["company"])))

    content = _to_json(refined_data)
    text_input = OTHER_TEXT_INPUT.format(
        count=actual_count, companies=companies, content=content
    )

    header = _make_header(
        button_label=button_label,
        expected=total_count,
        actual=actual_count,
    )

    result = openai_response(prompt=OTHER_PROMPT, input=text_input)

    used_links = ...  # result ì—ì„œ url ì‹ë³„
    try:
        _update_is_posted(tag, used_links)
    except Exception as e:
        logger.warning(f"update_is_posted failed ({tag}): {e}")

    return [f"[{button_label}]\n{header}\n{result}"]


def _handle_our_product(button_label: str) -> list[str]:
    keywords = KEYWORDS_BY_BUTTON[button_label]
    tag = BUTTON_TAG_MAP[button_label]
    extracted_data_count = 12
    dfs = _load_dataframes(tag)

    if not dfs:
        logger.warning("No source files found.")
        return [f"[{button_label}]\nìµœê·¼ 7ì¼ ë‚´ ì†Œì‹ì´ ì—†ì–´ìš” ğŸ˜Š"]

    data = pd.concat(dfs, ignore_index=True)
    data = filter_last_n_days_postdate(data, 7)

    if data.empty:
        logger.warning("No data after 7-day postdate filter.")
        return [f"[{button_label}]\nìµœê·¼ 7ì¼ ë‚´ ì†Œì‹ì´ ì—†ì–´ìš” ğŸ˜Š"]
    total_count = len(data)

    data = data.rename(columns={"postdate": "post_date"})

    refined_data = extract_high_score_data(
        data, keywords, CARD_COMPANIES, extracted_data_count
    )
    if len(refined_data) == 0:
        logger.warning("No data found after filtering.")
        return [
            "ì˜¤ëŠ˜ì€ ìì‚¬ ìƒí’ˆ ë°˜ì‘ ê´€ë ¨ ì£¼ëª©í• ë§Œí•œ ì´ìŠˆê°€ ì—†ì–´ìš”! ë‹¤ìŒì— ë” ì¢‹ì€ ì´ìŠˆë¡œ ì°¾ì•„ì˜¬ê²Œìš” ğŸ˜Š"
        ]

    refined_data["company"] = refined_data["title"].apply(_identify_company)
    actual_count = len(refined_data)
    product_name = button_label.replace(" ê³ ê°ë°˜ì‘", "")

    content = _to_json(refined_data)
    text_input = US_TEXT_INPUT.format(
        date=datetime.today().strftime("%Yë…„ %mì›” %dì¼"),
        product_name=product_name,
        count=actual_count,
        content=content,
    )

    header = _make_header(
        button_label=button_label,
        expected=total_count,
        actual=actual_count,
    )

    result = openai_response(prompt=US_PROMPT, input=text_input)

    used_links = ...  ## FIXME
    try:
        _update_is_posted(tag, used_links)
    except Exception as e:
        logger.warning(f"update_is_posted failed ({tag}): {e}")

    return [f"[{button_label}]\n{header}\n{result}"]
