import json
import re
from datetime import datetime

import pandas as pd
from openai import AsyncOpenAI, OpenAI

from bot.prompt import PROMPT, TEXT_INPUT
from data_collect.keywords import CARD_PRODUCTS, ISSUE_KEYWORDS
from secret import OPENAI_API_KEY
from variables import DATA_PATH

client = OpenAI(api_key=OPENAI_API_KEY)
async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


def _extract_urls(text: str) -> list[str]:
    urls = re.findall(r"https?://[^\s]+", text)
    return urls


class _FeedbackScorer:
    def __init__(
        self,
        issue_keywords: list[str],
        product_keywords: list[str],
    ):
        self.issue_keywords = issue_keywords
        self.product_keywords = product_keywords
        self.all_keywords = issue_keywords + product_keywords

    # scoring ê¸°ì¤€ 1: ë‚ ì§œê°€ ìµœì‹ ì¼ìˆ˜ë¡ ë†’ì€ ìŠ¤ì½”ì–´
    def calc_date_score(self, days: int) -> int:
        return sum([days <= 30, days <= 20, days <= 10])

    # scoring ê¸°ì¤€ 2: í•µì‹¬ í‚¤ì›Œë“œê°€ í¬í•¨ë ìˆ˜ë¡ ë†’ì€ ìŠ¤ì½”ì–´
    def calc_keyword_score(self, text: str) -> int:
        if any(kw in text for kw in self.issue_keywords):
            return 2
        elif any(kw in text for kw in self.product_keywords):
            return 1
        return 0

    # scoring ê¸°ì¤€ 3: ê¸€ì˜ ê¸¸ì´ ëŒ€ë¹„ ë¶€ì • ë‹¨ì–´ ì¹´ìš´íŠ¸ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ìŠ¤ì½”ì–´
    def count_negative_keywords(self, text: str) -> int:
        return sum(text.count(kw) for kw in self.issue_keywords)

    def assign_percentile_score(self, series: pd.Series) -> pd.Series:
        q90 = series.quantile(0.9)
        q80 = series.quantile(0.8)

        def score(val: float):
            return (val >= q80) + (val >= q90)

        return series.apply(score)

    # scoring ê¸°ì¤€ 4: ë¶€ì • ë‹¨ì–´ê°€ ìì£¼ ë°˜ë³µë ìˆ˜ë¡ ë†’ì€ ìŠ¤ì½”ì–´
    def score_by_repetition(self, text: str) -> int:
        for kw in self.all_keywords:
            pattern = rf"({re.escape(kw)})\1{{2,}}"
            if re.search(pattern, text):
                return 1
        return 0

    def apply_scores(
        self, df: pd.DataFrame, date_column: str = "post_date"
    ) -> pd.DataFrame:
        today = datetime.today()
        df = df.assign(
            post_date_dt=pd.to_datetime(
                df[date_column], format="%Y%m%d", errors="coerce"
            )
        )
        df = df.assign(days_diff=(today - df["post_date_dt"]).dt.days)

        df = df.assign(
            date_score=df["days_diff"].apply(self.calc_date_score),
            keyword_score=df["description"].fillna("").apply(self.calc_keyword_score),
            repetition_score=df["description"]
            .fillna("")
            .apply(self.score_by_repetition),
            neg_count_raw=df["description"]
            .fillna("")
            .apply(self.count_negative_keywords),
        )
        df = df.assign(
            neg_count_score=self.assign_percentile_score(df["neg_count_raw"]),
        )

        df = df.assign(
            total_score=(
                df["date_score"]
                + df["keyword_score"]
                + df["repetition_score"]
                + df["neg_count_score"]
            )
        )
        return df


def _refine_data(data: pd.DataFrame) -> pd.DataFrame:
    scorer = _FeedbackScorer(
        issue_keywords=ISSUE_KEYWORDS, product_keywords=CARD_PRODUCTS
    )
    _data = data[data["is_posted"] == 0]

    # ë¸”ë¡œê·¸ í•„í„°ë§
    data_blog = _data[_data["source"] == "blog"]
    data_blog = scorer.apply_scores(data_blog)
    data_blog = data_blog.sort_values(
        ["post_date", "total_score"], ascending=[False, False]
    ).iloc[:50]

    # ì¹´í˜ í•„í„°ë§
    data_cafe = _data[_data["source"] == "cafe"]
    data_cafe = scorer.apply_scores(data_cafe)
    data_cafe = data_cafe.sort_values("total_score", ascending=False).iloc[:50]

    # ë³‘í•©í•˜ì—¬ ë°˜í™˜
    return pd.concat([data_blog, data_cafe], ignore_index=True)


def get_issue_message(data: pd.DataFrame) -> str:
    refined_data = _refine_data(data)
    content = json.dumps(
        refined_data[["title", "link", "description"]].to_dict(orient="records"),
        ensure_ascii=False,
    )
    response = client.responses.create(
        model="gpt-4o",
        instructions=PROMPT,
        input=TEXT_INPUT.format(
            card_products=", ".join(CARD_PRODUCTS),
            content=content,
        ),
    )
    result = response.output_text.strip()
    message = (
        f"ì•ˆë…•í•˜ì„¸ìš”! ì¤ì¤ì´ì…ë‹ˆë‹¤ ğŸ¤—\n{datetime.today().strftime('%Yë…„ %mì›” %dì¼')} ì¤ì¤í•œ ì´ìŠˆë¥¼ ê³µìœ ë“œë¦´ê²Œìš”!\nìˆ˜ì§‘í•œ ì´ {len(data)}ê°œì˜ ë¬¸ì„œë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤!\n"
        + result
    )
    urls = _extract_urls(result)

    if len(urls) == 0:
        print("No URLs found in the message.")
    else:
        if len(urls) != 2:
            print("Not expected number of URLs found in the message.")
        data.loc[data["link"].isin(urls), "is_posted"] = 1

    data.to_csv(DATA_PATH, index=False, encoding="utf-8")
    return message
